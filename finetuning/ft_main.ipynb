{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifiable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make sure that there are csv files named \n",
    "f'{trainset_name}.csv' and f'{testset_name}.csv' in the csvs folder\n",
    "\"\"\"\n",
    "\n",
    "trainset_name = 'ETTh2'\n",
    "testset_name = 'ETTh2_test'\n",
    "\n",
    "model_name = 'moirai_1.0_R_small'\n",
    "run_name = 'test-02'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & validation datasets vreation from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███| 7/7 [00:00<00:00, 1236.22 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|███| 7/7 [00:00<00:00, 1245.76 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|███| 7/7 [00:00<00:00, 1174.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_val_creation_command = f\"python -m uni2ts.data.builder.simple \\\n",
    "                                {trainset_name} ./csvs/{trainset_name}.csv \\\n",
    "                                    --dataset_type wide --date_offset '2017-10-23 23:00:00'\"\n",
    "\n",
    "test_creation_command = f\"python -m uni2ts.data.builder.simple \\\n",
    "                            {testset_name} ./csvs/{testset_name}.csv \\\n",
    "                                --dataset_type wide\"\n",
    "\n",
    "!{train_val_creation_command}\n",
    "!{test_creation_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_config_path = './conf/finetune/default.yaml'\n",
    "eval_config_path = './conf/eval/default.yaml'\n",
    "\n",
    "with open(finetune_config_path, 'r') as file:\n",
    "    finetune_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "with open(eval_config_path, 'r') as file:\n",
    "    eval_config = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data yaml files\n",
    "train_sample_data_cfg_path = './conf/finetune/data/etth1.yaml'\n",
    "val_sample_data_cfg_path = './conf/finetune/val_data/etth1.yaml'\n",
    "test_sample_data_cfg_path = './conf/eval/data/etth1_test.yaml'\n",
    "\n",
    "with open(train_sample_data_cfg_path, 'r') as file:\n",
    "    train_sample_data_cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "with open(val_sample_data_cfg_path, 'r') as file:\n",
    "    val_sample_data_cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "with open(test_sample_data_cfg_path, 'r') as file:\n",
    "    test_sample_data_cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# update the config files with the new dataset names\n",
    "train_sample_data_cfg['dataset'] = trainset_name\n",
    "val_sample_data_cfg['_args_']['dataset'] = trainset_name + '_eval'\n",
    "test_sample_data_cfg['dataset_name'] = testset_name\n",
    "\n",
    "# save the updated config files\n",
    "train_data_cfg_path = f'./conf/finetune/data/{trainset_name.lower()}.yaml'\n",
    "val_data_cfg_path = f'./conf/finetune/val_data/{trainset_name.lower()}.yaml'\n",
    "test_data_cfg_path = f'./conf/eval/data/{testset_name.lower()}.yaml'\n",
    "\n",
    "with open(train_data_cfg_path, 'w') as file:\n",
    "    yaml.dump(train_sample_data_cfg, file)\n",
    "\n",
    "with open(val_data_cfg_path, 'w') as file:\n",
    "    yaml.dump(val_sample_data_cfg, file)\n",
    "\n",
    "with open(test_data_cfg_path, 'w') as file:\n",
    "    yaml.dump(test_sample_data_cfg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config['defaults'][0]['model'] = model_name\n",
    "eval_config['defaults'][1]['data'] = testset_name.lower()\n",
    "eval_config['run_name'] = run_name\n",
    "\n",
    "with open(eval_config_path, 'w') as file:\n",
    "    yaml.dump(eval_config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_config['defaults'][0]['model'] = model_name\n",
    "finetune_config['defaults'][1]['data'] = trainset_name.lower()\n",
    "finetune_config['defaults'][2]['val_data'] = trainset_name.lower()\n",
    "finetune_config['run_name'] = run_name\n",
    "\n",
    "eval_config['defaults'][0]['model'] = model_name\n",
    "# eval_config['defaults'][1]['data'] = testset_name.lower()\n",
    "eval_config['run_name'] = run_name\n",
    "\n",
    "# save the updated config files\n",
    "with open(finetune_config_path, 'w') as file:\n",
    "    yaml.dump(finetune_config, file)\n",
    "\n",
    "with open(eval_config_path, 'w') as file:\n",
    "    yaml.dump(eval_config, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-19 13:34:59,073][numexpr.utils][INFO] - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2024-05-19 13:34:59,073][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.\n",
      "trainable parameters:\n",
      "trainable params: 350,208 || all params: 14,177,736 || trainable%: 2.470126400999426\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[2024-05-19 13:35:02,113][datasets][INFO] - PyTorch version 2.3.0 available.\n",
      "[2024-05-19 13:35:02,114][datasets][INFO] - JAX version 0.4.28 available.\n",
      "Missing logger folder: /sise/home/liornis/thesis/research-experiments-env/finetuning/outputs/train/moirai_1.0_R_small/etth2/test-02/logs\n",
      "[rank: 0] Seed set to 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type         | Params\n",
      "----------------------------------------\n",
      "0 | module | MoiraiModule | 14.2 M\n",
      "----------------------------------------\n",
      "350 K     Trainable params\n",
      "13.8 M    Non-trainable params\n",
      "14.2 M    Total params\n",
      "56.711    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Epoch 0: |          | 3/? [00:01<00:00,  2.09it/s, v_num=0]                \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation DataLoader 0: |          | 1/? [00:01<00:00,  0.76it/s]\n",
      "Validation DataLoader 0: |          | 2/? [00:03<00:00,  0.64it/s]\n",
      "Validation DataLoader 0: |          | 3/? [00:04<00:00,  0.60it/s]\n",
      "Validation DataLoader 0: |          | 4/? [00:06<00:00,  0.58it/s]\n",
      "Validation DataLoader 0: |          | 5/? [00:08<00:00,  0.58it/s]\n",
      "Validation DataLoader 0: |          | 6/? [00:10<00:00,  0.57it/s]\n",
      "Validation DataLoader 0: |          | 7/? [00:12<00:00,  0.57it/s]\n",
      "Validation DataLoader 0: |          | 8/? [00:14<00:00,  0.57it/s]\n",
      "Validation DataLoader 0: |          | 9/? [00:15<00:00,  0.57it/s]\n",
      "Validation DataLoader 0: |          | 10/? [00:17<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 11/? [00:19<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 12/? [00:21<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 13/? [00:23<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 14/? [00:25<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 15/? [00:26<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 16/? [00:28<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 17/? [00:30<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 18/? [00:32<00:00,  0.56it/s]\n",
      "Validation DataLoader 0: |          | 19/? [00:33<00:00,  0.56it/s]\n",
      "Metric val/PackedNRMSELoss improved. New best score: 0.975\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: |          | 3/? [00:36<00:00,  0.08it/s, v_num=0, val/PackedNLLLoss=8.620, val/PackedMSELoss=347.0, val/PackedNRMSELoss=0.975, train/PackedNLLLoss=3.490]\n",
      "/storage/modules/packages/anaconda/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!srun python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-19 13:36:21,422][datasets][INFO] - PyTorch version 2.3.0 available.\n",
      "[2024-05-19 13:36:21,424][datasets][INFO] - JAX version 0.4.28 available.\n",
      "trainable parameters:\n",
      "trainable params: 350,208 || all params: 14,177,736 || trainable%: 2.470126400999426\n",
      "19495it [01:50, 175.82it/s]176.05it/s]\n",
      "{'MSE[mean]': {None: 13.224520301345965}, 'MSE[0.5]': {None: 13.333621448283013}, 'MAE[0.5]': {None: 2.366374969547647}, 'MASE[0.5]': {None: 0.9868416217518357}, 'MAPE[0.5]': {None: 0.17066965648032656}, 'sMAPE[0.5]': {None: 0.21131828067098263}, 'MSIS': {None: 6.96813247693623}, 'RMSE[mean]': {None: 3.636553354667846}, 'NRMSE[mean]': {None: 0.20803808381485075}, 'ND[0.5]': {None: 0.1353743685955306}, 'mean_weighted_sum_quantile_loss': {None: 0.106164790897128}}\n"
     ]
    }
   ],
   "source": [
    "!srun python eval.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ln_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
