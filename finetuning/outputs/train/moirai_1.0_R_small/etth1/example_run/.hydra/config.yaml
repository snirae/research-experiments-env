model:
  _target_: uni2ts.model.moirai.MoiraiFinetune.load_from_checkpoint
  module_kwargs:
    _target_: builtins.dict
    distr_output:
      _target_: uni2ts.distribution.MixtureOutput
      components:
      - _target_: uni2ts.distribution.StudentTOutput
      - _target_: uni2ts.distribution.NormalFixedScaleOutput
      - _target_: uni2ts.distribution.NegativeBinomialOutput
      - _target_: uni2ts.distribution.LogNormalOutput
    d_model: 384
    num_layers: 6
    patch_sizes: ${as_tuple:[8, 16, 32, 64, 128]}
    max_seq_len: 512
    attn_dropout_p: 0.0
    dropout_p: 0.0
    scaling: true
  min_patches: 2
  min_mask_ratio: 0.15
  max_mask_ratio: 0.5
  max_dim: 128
  loss_func:
    _target_: uni2ts.loss.packed.PackedNLLLoss
  val_metric:
  - _target_: uni2ts.loss.packed.PackedMSELoss
  - _target_: uni2ts.loss.packed.PackedNRMSELoss
    normalize: absolute_target_squared
  lr: 0.001
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.98
  num_training_steps: ${mul:${trainer.max_epochs},${train_dataloader.num_batches_per_epoch}}
  num_warmup_steps: 0
  checkpoint_path:
    _target_: huggingface_hub.hf_hub_download
    repo_id: Salesforce/moirai-1.0-R-small
    filename: model.ckpt
data:
  _target_: uni2ts.data.builder.simple.SimpleDatasetBuilder
  dataset: ETTh1
  weight: 1000
val_data:
  _target_: uni2ts.data.builder.ConcatDatasetBuilder
  _args_:
    _target_: uni2ts.data.builder.simple.generate_eval_builders
    dataset: ETTh1_eval
    offset: 11520
    eval_length: 2880
    prediction_lengths:
    - 96
    - 192
    - 336
    - 720
    context_lengths:
    - 1000
    - 2000
    - 3000
    - 4000
    - 5000
    patch_sizes:
    - 32
    - 64
run_name: example_run
seed: 0
tf32: true
compile: false
trainer:
  _target_: lightning.Trainer
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 32
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${hydra:runtime.output_dir}
    name: logs
  callbacks:
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${hydra:runtime.output_dir}/checkpoints
    monitor: val/PackedNLLLoss
    save_weights_only: true
    mode: min
    save_top_k: 1
    every_n_epochs: 1
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val/PackedNLLLoss
    min_delta: 0.0
    patience: 3
    mode: min
    strict: false
    verbose: true
  max_epochs: 100
  enable_progress_bar: true
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
train_dataloader:
  _target_: uni2ts.data.loader.DataLoader
  batch_size: 32
  batch_size_factor: 2.0
  cycle: true
  num_batches_per_epoch: 100
  shuffle: true
  num_workers: 11
  collate_fn:
    _target_: uni2ts.data.loader.PackCollate
    max_length: ${model.module_kwargs.max_seq_len}
    seq_fields: ${cls_getattr:${model._target_},seq_fields}
    pad_func_map: ${cls_getattr:${model._target_},pad_func_map}
  pin_memory: true
  drop_last: false
  fill_last: false
  worker_init_fn: null
  prefetch_factor: 2
  persistent_workers: true
val_dataloader:
  _target_: uni2ts.data.loader.DataLoader
  batch_size: 32
  batch_size_factor: 2.0
  cycle: false
  num_batches_per_epoch: null
  shuffle: false
  num_workers: 11
  collate_fn:
    _target_: uni2ts.data.loader.PackCollate
    max_length: ${model.module_kwargs.max_seq_len}
    seq_fields: ${cls_getattr:${model._target_},seq_fields}
    pad_func_map: ${cls_getattr:${model._target_},pad_func_map}
  pin_memory: false
  drop_last: false
  fill_last: true
  worker_init_fn: null
  prefetch_factor: 2
  persistent_workers: true
