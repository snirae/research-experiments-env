model:
  _target_: uni2ts.model.moirai.MoiraiFinetune.load_from_checkpoint
  beta1: 0.9
  beta2: 0.98
  checkpoint_path:
    _target_: huggingface_hub.hf_hub_download
    filename: model.ckpt
    repo_id: Salesforce/moirai-1.0-R-small
  loss_func:
    _target_: uni2ts.loss.packed.PackedNLLLoss
  lr: 0.001
  max_dim: 128
  max_mask_ratio: 0.5
  min_mask_ratio: 0.15
  min_patches: 2
  module_kwargs:
    _target_: builtins.dict
    attn_dropout_p: 0.0
    d_model: 384
    distr_output:
      _target_: uni2ts.distribution.MixtureOutput
      components:
      - _target_: uni2ts.distribution.StudentTOutput
      - _target_: uni2ts.distribution.NormalFixedScaleOutput
      - _target_: uni2ts.distribution.NegativeBinomialOutput
      - _target_: uni2ts.distribution.LogNormalOutput
    dropout_p: 0.0
    max_seq_len: 512
    num_layers: 6
    patch_sizes: ${as_tuple:[8, 16, 32, 64, 128]}
    scaling: true
  num_training_steps: ${mul:${trainer.max_epochs},${train_dataloader.num_batches_per_epoch}}
  num_warmup_steps: 0
  val_metric:
  - _target_: uni2ts.loss.packed.PackedMSELoss
  - _target_: uni2ts.loss.packed.PackedNRMSELoss
    normalize: absolute_target_squared
  weight_decay: 0.1
data:
  _target_: uni2ts.data.builder.simple.SimpleDatasetBuilder
  dataset: ETTh2
  weight: 1000
val_data:
  _args_:
    _target_: uni2ts.data.builder.simple.generate_eval_builders
    context_lengths:
    - 1000
    - 2000
    - 3000
    - 4000
    - 5000
    dataset: ETTh2_eval
    eval_length: 2880
    offset: 11520
    patch_sizes:
    - 32
    - 64
    prediction_lengths:
    - 96
    - 192
    - 336
    - 720
  _target_: uni2ts.data.builder.ConcatDatasetBuilder
compile: false
run_name: test-02
seed: 0
tf32: true
train_dataloader:
  _target_: uni2ts.data.loader.DataLoader
  batch_size: 32
  batch_size_factor: 2.0
  collate_fn:
    _target_: uni2ts.data.loader.PackCollate
    max_length: ${model.module_kwargs.max_seq_len}
    pad_func_map: ${cls_getattr:${model._target_},pad_func_map}
    seq_fields: ${cls_getattr:${model._target_},seq_fields}
  cycle: true
  drop_last: false
  fill_last: false
  num_batches_per_epoch: 3
  num_workers: 2
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 2
  shuffle: true
  worker_init_fn: null
trainer:
  _target_: lightning.Trainer
  accelerator: auto
  accumulate_grad_batches: 1
  callbacks:
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${hydra:runtime.output_dir}/checkpoints
    every_n_epochs: 1
    mode: min
    monitor: val/PackedNRMSELoss
    save_top_k: 1
    save_weights_only: true
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    min_delta: 0.0
    mode: min
    monitor: val/PackedNRMSELoss
    patience: 3
    strict: false
    verbose: true
  devices: auto
  enable_progress_bar: true
  gradient_clip_algorithm: norm
  gradient_clip_val: 1.0
  logger:
    _target_: lightning.pytorch.loggers.TensorBoardLogger
    name: logs
    save_dir: ${hydra:runtime.output_dir}
  max_epochs: 1
  num_nodes: 1
  precision: 32
  strategy: auto
val_dataloader:
  _target_: uni2ts.data.loader.DataLoader
  batch_size: 32
  batch_size_factor: 2.0
  collate_fn:
    _target_: uni2ts.data.loader.PackCollate
    max_length: ${model.module_kwargs.max_seq_len}
    pad_func_map: ${cls_getattr:${model._target_},pad_func_map}
    seq_fields: ${cls_getattr:${model._target_},seq_fields}
  cycle: false
  drop_last: false
  fill_last: true
  num_batches_per_epoch: null
  num_workers: 2
  persistent_workers: true
  pin_memory: false
  prefetch_factor: 2
  shuffle: false
  worker_init_fn: null
